{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import argparse\n",
    "import pickle\n",
    "import torch\n",
    "import json\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from esim.data import NLIDataset\n",
    "from esim.model import ESIM\n",
    "from esim.utils_train import train, validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from esim.data_reader import Preprocessor\n",
    "from esim.data_reader import NLIDataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from esim.data_reader import data_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing embeddings matrix...\n",
      "12257\n",
      "12259\n",
      "第一届\n",
      "扎得\n",
      "前金院\n",
      "几年\n",
      "部该\n",
      "是旦\n",
      "花衫\n",
      "取个\n",
      "多吃生\n",
      "银保\n",
      "心智健全\n",
      "选拔干部\n",
      "几首\n",
      "一步\n",
      "计财部\n",
      "本特\n",
      "岗平\n",
      "存点\n",
      "说水\n",
      "机是\n",
      "付额\n",
      "爸姓\n",
      "几楼\n",
      "第一部\n",
      "说会\n",
      "武旦\n",
      "版先\n",
      "触电时\n",
      "慢病\n",
      "喝咖啡\n",
      "能买个\n",
      "四片\n",
      "几句\n",
      "有延项\n",
      "做二便\n",
      "瓷质\n",
      "几下\n",
      "15%\n",
      "五十多岁\n",
      "爱是\n",
      "第一件\n",
      "总支部\n",
      "需哟\n",
      "两定\n",
      "多血\n",
      "喝多\n",
      "几个\n",
      "具体表\n",
      "若得\n",
      "一个月\n",
      "完步\n",
      "B超\n",
      "三方\n",
      "长是\n",
      "得直\n",
      "肖总\n",
      "多个\n",
      "几句话\n",
      "想美白\n",
      "说点\n",
      "廖俊波\n",
      "一部\n",
      "双录\n",
      "人有\n",
      "一次\n",
      "金要\n",
      "高菁\n",
      "双查\n",
      "二十多\n",
      "混着\n",
      "挺大\n",
      "管瘤\n",
      "党执政\n",
      "付线\n",
      "党风廉政\n",
      "吃生\n",
      "3T\n",
      "报灯\n",
      "三十多岁\n",
      "中国新民主主义革命\n",
      "乐一乐\n",
      "孔庆伟\n",
      "没换\n",
      "一届\n",
      "一台\n",
      "X射线\n",
      "讲个\n",
      "有家\n",
      "VISA卡\n",
      "五条\n",
      "包不包\n",
      "贷是\n",
      "我帅\n",
      "发量\n",
      "一棵\n",
      "起付\n",
      "要少\n",
      "弃项\n",
      "卡制作\n",
      "前应\n",
      "太牛\n",
      "不流\n",
      "我能\n",
      "能聊\n",
      "区指\n",
      "六有\n",
      "薪易贷\n",
      "口病\n",
      "做直\n",
      "一点点\n",
      "上能\n",
      "我姓\n",
      "好萌\n",
      "一有\n",
      "老掉\n",
      "一首\n",
      "合要\n",
      "这点\n",
      "太干\n",
      "易使\n",
      "陈园\n",
      "针口\n",
      "我用\n",
      "几分钟\n",
      "每分\n",
      "三甲\n",
      "人多\n",
      "几首歌\n",
      "一步步\n",
      "严治\n",
      "加项\n",
      "没电是\n",
      "四条\n",
      "我办\n",
      "帮个\n",
      "好几年\n",
      "期收\n",
      "好少\n",
      "爱眼日\n",
      "五水共治\n",
      "卖个\n",
      "第十\n",
      "跳个\n",
      "有何\n",
      "六十多\n",
      "笑个\n",
      "两个\n",
      "三型\n",
      "需经\n",
      "能值\n",
      "天能\n",
      "四十多岁\n",
      "不多\n",
      "说个\n",
      "扎过\n",
      "费缓\n",
      "总吃\n",
      "相适\n",
      "事是\n",
      "诊有\n",
      "三位\n",
      "缺碘有\n",
      "第二批\n",
      "抵支\n",
      "合新\n",
      "一座\n",
      "病有\n",
      "好大\n",
      "另一只\n",
      "太瘦会\n",
      "奶及\n",
      "一句\n",
      "延项\n",
      "第十九届\n",
      "姚军\n",
      "老顶\n",
      "爱德\n",
      "用网\n",
      "骤停\n",
      "笨点\n",
      "外配\n",
      "哪一点\n",
      "五十多\n",
      "真如铁\n",
      "党应\n",
      "能报\n",
      "我码\n",
      "过轻会\n",
      "一种\n",
      "十杯\n",
      "没掉\n",
      "五水共治指\n",
      "讲人话\n",
      "取卡\n",
      "后要\n",
      "二批\n",
      "一群\n",
      "几种\n",
      "四性\n",
      "一是\n",
      "二便\n",
      "三个\n",
      "几分\n",
      "术后\n",
      "做个\n",
      "要分\n",
      "你会\n",
      "两句话\n",
      "有弃\n",
      "X光\n",
      "六个\n",
      "多岁\n",
      "没带\n",
      "卡到\n",
      "几本书\n",
      "毛净\n",
      "孕前\n",
      "我要\n",
      "还会\n",
      "熟食品\n",
      "下天\n",
      "姜坏\n",
      "哪来\n",
      "加酶\n",
      "黄宝\n",
      "完血\n",
      "一杯\n",
      "生旦\n",
      "阔落\n",
      "前要\n",
      "中有\n",
      "安博士\n",
      "时恒\n",
      "生角\n",
      "默比\n",
      "大是\n",
      "钱算\n",
      "五种\n",
      "几辆\n",
      "要放\n",
      "有车\n",
      "保险期\n",
      "哪读\n",
      "不需\n",
      "最多人\n",
      "两种\n",
      "给爷\n",
      "费由\n",
      "生是\n",
      "缴钱\n",
      "弃检\n",
      "缓缴\n",
      "供血\n",
      "人上\n",
      "需提交\n",
      "取号\n",
      "一岗双责\n",
      "哪三大\n",
      "一段\n",
      "几月\n",
      "变胖\n",
      "一指\n",
      "大规\n",
      "人一保\n",
      "最帅\n",
      "几杯\n",
      "划账\n",
      "曲种\n",
      "我爱你\n",
      "归宿点\n",
      "首个\n",
      "一天\n",
      "合有\n",
      "孙建\n",
      "好多好多\n",
      "完酸\n",
      "劳逸\n",
      "过生日\n",
      "三严\n",
      "只会\n",
      "五百强\n",
      "睡够\n",
      "保护环\n",
      "总起\n",
      "聊点\n",
      "C13\n",
      "一核\n",
      "我点\n",
      "叫单\n",
      "瓷具\n",
      "十多岁\n",
      "我取\n",
      "几号\n",
      "挺萌\n",
      "还会点\n",
      "党的性质\n",
      "爱牙日\n",
      "一棵树\n",
      "几十\n",
      "膝关\n",
      "刚烤\n",
      "优斯\n",
      "四项\n",
      "替牙\n",
      "前能\n",
      "多少岁\n",
      "生女生\n",
      "内障\n",
      "烦烦\n",
      "一周\n",
      "没坏\n",
      "老旦\n",
      "长不长\n",
      "太瘦\n",
      "新举措\n",
      "脸会动\n",
      "新党章\n",
      "检后\n",
      "矮桌\n",
      "肖建荣\n",
      "门慢\n",
      "曹实\n",
      "赣西\n",
      "做点\n",
      "沟有\n",
      "能为\n",
      "吃太急\n",
      "爷乐\n",
      "喝冰\n",
      "第一次\n",
      "报灯名\n",
      "孙建平\n",
      "牙萌出\n",
      "十年\n",
      "几岁\n",
      "二维\n",
      "一课\n",
      "统帐\n",
      "四个坚持\n",
      "几小时\n",
      "喝太多\n",
      "沟是\n",
      "长得帅\n",
      "一人\n",
      "第三方\n",
      "哪支\n",
      "从何\n",
      "次为\n",
      "三十多\n",
      "第一枪\n",
      "你值\n",
      "一项\n",
      "蜡水\n",
      "唱个\n",
      "想生\n",
      "口病会\n",
      "四种\n",
      "几天\n",
      "陈克祥\n",
      "京市\n",
      "七项\n",
      "有个\n",
      "支股\n",
      "几口\n",
      "哪类\n",
      "第十九\n",
      "天好\n",
      "净角\n",
      "这是\n",
      "一年\n",
      "检前\n",
      "备孕时\n",
      "一套\n",
      "爱耳日\n",
      "生旦净\n",
      "扎到\n",
      "谢永林\n",
      "八项\n",
      "法对\n",
      "三区\n",
      "血会\n",
      "使加\n",
      "要充\n",
      "会怕\n",
      "而建\n",
      "干有\n",
      "小妙\n",
      "查直\n",
      "加是\n",
      "办园\n",
      "做些\n",
      "一保\n",
      "合是\n",
      "五位\n",
      "一日\n",
      "美白能\n",
      "陈立明\n",
      "你会点\n",
      "城是\n",
      "部在\n",
      "三餐\n",
      "真烂\n",
      "几次\n",
      "两句\n",
      "六字\n",
      "紧有\n",
      "我来\n",
      "睡太多\n",
      "多大\n",
      "无烟日\n",
      "七个\n",
      "武丑\n",
      "费不全\n",
      "胃好\n",
      "好慢\n",
      "几辆车\n",
      "不差\n",
      "那本书\n",
      "这一\n",
      "九届\n",
      "平片\n",
      "剂用\n",
      "几十年\n",
      "眼得\n",
      "中应\n",
      "材能\n",
      "几家\n",
      "聊下\n",
      "两大\n",
      "扫码\n",
      "离退\n",
      "喝久\n",
      "第十九次\n",
      "过低\n",
      "克奶\n",
      "毒饵\n",
      "一招\n",
      "有房\n",
      "哪五水\n",
      "五点\n",
      "应食入\n",
      "江泽\n",
      "正净\n",
      "来个\n",
      "几点\n",
      "三大作风\n",
      "电图\n",
      "十多\n",
      "宣传日\n",
      "灭蝇\n",
      "情为\n",
      "管理制\n",
      "好觉\n",
      "一百年\n",
      "完药\n",
      "一案\n",
      "我以\n",
      "刀马\n",
      "姜烂\n",
      "一只\n",
      "问中\n",
      "另约\n",
      "沟指\n",
      "第三\n",
      "烦到\n",
      "重疾\n",
      "搭个\n",
      "多远\n",
      "社平\n",
      "醋水\n",
      "线上\n",
      "哪座\n",
      "几颗\n",
      "舒适型\n",
      "手变\n",
      "谁生\n",
      "黄段子\n",
      "限行\n",
      "生吃\n",
      "六十多岁\n",
      "帮人\n",
      "紧会\n",
      "烛油\n",
      "保险期限\n",
      "不缺\n",
      "杀精\n",
      "三会\n",
      "法杀\n",
      "呆萌\n",
      "一条\n",
      "每分钟\n",
      "或物\n",
      "姜能\n",
      "胖症\n",
      "人能\n",
      "干些\n",
      "四风\n",
      "四十多\n",
      "十杯水\n",
      "应带\n",
      "生旦净末\n",
      "好发\n",
      "统账\n",
      "玩忽\n",
      "取点\n",
      "五位一体\n",
      "人去\n",
      "多项\n",
      "一支\n",
      "萌呀\n",
      "甲型肝炎\n",
      "后能\n",
      "不动会\n",
      "两学\n",
      "下要\n",
      "年版\n",
      "常吃\n",
      "哪条\n",
      "这句\n",
      "几本\n",
      "二十多岁\n",
      "人变\n",
      "四个\n",
      "就够\n",
      "哪修\n",
      "美醇\n",
      "职工基本\n",
      "前有\n",
      "洗才\n",
      "万是\n",
      "我想作\n",
      "湘东\n",
      "购药\n",
      "吃面\n",
      "龈炎\n",
      "一件\n",
      "九次\n",
      "五线\n",
      "同吃\n",
      "11718 words find 539 lost in our vocabulary had w2v vectors and appear more than the min frequency\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('../data/train_data20.csv')\n",
    "train_data=train_data.sample(frac=1).reset_index(drop=True)\n",
    "test_data=pd.read_csv('../data/test_data.csv')\n",
    "processor=Preprocessor()\n",
    "train_data=processor.seg_data(train_data)\n",
    "test_data=processor.seg_data(test_data)\n",
    "word_set=processor.set_data(train_data)|processor.set_data(test_data)\n",
    "\n",
    "embeddings_index=processor.read_embedding()\n",
    "##词向量原始10000条与新数据的并集为新的embedingmatrix的索引\n",
    "word_set=set([i for i in embeddings_index.keys()][:10000])|word_set\n",
    "\n",
    "embedding_matrix,word_to_indices=processor.build_embedding_matrix(word_set,embeddings_index)\n",
    "\n",
    "train_esim=processor.gen_input_data(train_data,word_to_indices)\n",
    "valid_esim=processor.gen_input_data(test_data,word_to_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 300\n",
    "dropout = 0.3\n",
    "num_classes = 2\n",
    "epochs = 4\n",
    "batch_size =256\n",
    "lr = 0.0004\n",
    "patience = 5\n",
    "max_grad_norm = 10\n",
    "checkpoint = False\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "save_flag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t* Loading training data...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\t* Loading training data...\")\n",
    "max_len=20\n",
    "Ntrain = NLIDataset(train_esim, padding_idx=1, max_premise_length=max_len, max_hypothesis_length=max_len)\n",
    "Nvalid = NLIDataset(valid_esim, padding_idx=1, max_premise_length=max_len, max_hypothesis_length=max_len)\n",
    "train_loader = DataLoader(Ntrain, shuffle=False, batch_size=batch_size)\n",
    "valid_loader = DataLoader(Nvalid, shuffle=False, batch_size=batch_size)\n",
    "embeddings = torch.tensor(embedding_matrix, dtype=torch.float).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path='esim_model.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/483 [00:00<?, ?it/s]/home/su/HL/FQA/ESIM/esim/utils.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
      "  sequences_lengths.new_tensor(torch.arange(0, len(sequences_lengths)))\n",
      "Avg. batch proc. time: 0.1468s, loss: 0.6911:   0%|          | 1/483 [00:00<01:27,  5.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ==================== Training ESIM model on device: cuda:0 ====================\n",
      "* Training epoch 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0661s, loss: 0.1996: 100%|██████████| 483/483 [00:34<00:00, 14.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 34.1987s, loss = 0.1996, accuracy: 91.5262%\n",
      "* Validation for epoch 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0648s, loss: 0.1331:   0%|          | 2/483 [00:00<00:33, 14.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t* Validation auc before training: 94.6048%, accuracy (0.85): 88.4722%\n",
      "* Training epoch 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0668s, loss: 0.1037: 100%|██████████| 483/483 [00:34<00:00, 14.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 34.4630s, loss = 0.1037, accuracy: 96.2723%\n",
      "* Validation for epoch 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0674s, loss: 0.0567:   0%|          | 0/483 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t* Validation auc before training: 94.7758%, accuracy (0.85): 89.0615%\n",
      "* Training epoch 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0676s, loss: 0.0747: 100%|██████████| 483/483 [00:34<00:00, 13.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 34.9032s, loss = 0.0747, accuracy: 97.3563%\n",
      "* Validation for epoch 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0672s, loss: 0.0491:   0%|          | 2/483 [00:00<00:34, 13.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t* Validation auc before training: 95.7367%, accuracy (0.85): 89.9812%\n",
      "* Training epoch 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0678s, loss: 0.0564: 100%|██████████| 483/483 [00:34<00:00, 13.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 34.9508s, loss = 0.0564, accuracy: 98.0383%\n",
      "* Validation for epoch 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0676s, loss: 0.0566:   0%|          | 2/483 [00:00<00:34, 13.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t* Validation auc before training: 94.9594%, accuracy (0.85): 88.9187%\n",
      "* Training epoch 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. batch proc. time: 0.0688s, loss: 0.0455: 100%|██████████| 483/483 [00:35<00:00, 13.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Training time: 35.4795s, loss = 0.0455, accuracy: 98.4169%\n",
      "* Validation for epoch 4:\n",
      "\t* Validation auc before training: 94.0788%, accuracy (0.85): 87.7757%\n"
     ]
    }
   ],
   "source": [
    "model = ESIM(embeddings.shape[0],\n",
    "             embeddings.shape[1],\n",
    "             hidden_size,\n",
    "             embeddings=embeddings,\n",
    "             padding_idx=1,\n",
    "             dropout=dropout,\n",
    "             num_classes=num_classes,\n",
    "             device=device).to(device)\n",
    "\n",
    "# -------------------- Preparation for training  ------------------- #\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                       mode=\"max\",\n",
    "                                                       factor=0.5,\n",
    "                                                       patience=0)\n",
    "\n",
    "Best_auc=0\n",
    "# -------------------- Training epochs ------------------- #\n",
    "print(\"\\n\",\n",
    "      20 * \"=\",\n",
    "      \"Training ESIM model on device: {}\".format(device),\n",
    "      20 * \"=\")\n",
    "\n",
    "patience_counter = 0\n",
    "for epoch in range(0, epochs+1):\n",
    "    print(\"* Training epoch {}:\".format(epoch))\n",
    "    model,epoch_time, epoch_loss, epoch_accuracy = train(model,\n",
    "                                                   train_loader,\n",
    "                                                   optimizer,\n",
    "                                                   criterion,\n",
    "                                                   epoch,\n",
    "                                                   max_grad_norm)\n",
    "    print(\"-> Training time: {:.4f}s, loss = {:.4f}, accuracy: {:.4f}%\"\n",
    "          .format(epoch_time, epoch_loss, (epoch_accuracy*100)))\n",
    "\n",
    "    print(\"* Validation for epoch {}:\".format(epoch))   \n",
    "    _, auc,acc = validate(model, valid_loader,criterion)\n",
    "    print(\"\\t* Validation auc before training: {:.4f}%, accuracy (0.85): {:.4f}%\"\n",
    "          .format(auc*100, acc*100))\n",
    "    if auc>Best_auc:\n",
    "        Best_auc=auc\n",
    "        torch.save(model,'model.pkl')\n",
    "    # Update the optimizer's learning rate with the scheduler.\n",
    "    scheduler.step(epoch_accuracy)\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"-> Early stopping: patience limit reached, stopping...\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型存储"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model,'model.pkl')\n",
    "import json \n",
    "with open('word_to_indices.json','w') as f:\n",
    "    json.dump(word_to_indices,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
